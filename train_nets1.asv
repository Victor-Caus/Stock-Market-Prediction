% 1. Coleta de dados:
% Aqui deverá ser coletado os dados de entrada e saída do Excell


tablePETR = readtable('PETR3.xlsx');
tableVALE = readtable('VALE3.xlsx');
tableEMBR = readtable('EMBR3.xlsx');
close = cell(1, 3);
close{1} = tablePETR{:, 7};
close{2} = tableVALE{:, 7};
close{3} = tableEMBR{:, 7};


T = cell(1, 3); % sera uma celula de matrizes onde T{1} é da PETR, T{2} é da VALE, T{3} é da EMBR. 
nAmostras = floor(size(close{1},1)/10) - 1;
P = zeros(30, nAmostras); % padrões de entrada

% organizando as amostras
for i = 1:nAmostras
    % pegar os fechamentos "atrasados" das três:
    P(:,i) = [close{1}(10*i - 9 : 10*i) ; close{2}(10*i - 9 : 10*i) ; close{3}(10*i - 9 : 10*i)];
    
    % para cada uma, pegar a saída como sendo os fechamentos adiantados:
    for j = 1:3
        T{j}(:,i) = [close{j}(10*(i+1) - 9 : 10*(i+1))];
    end
end

%Variáveis importantes:
nSimulacao = 90; % (referente aos ultimos 3 meses)
indiceMaxTrein = nAmostras - nSimulacao;
% Separando os que vao ser treinados do total:
Ptr = P(1:indiceMaxTrein);
Ttr = T(1:indiceMaxTrein);


% 2.Construção das Redes de arquitetura MLP, seguindo a ordem convencionada
nets = cell(1, 3); % vetor contendo as respectivas redes neurais
for i = 1:3
    nets{i} = feedforwardnet(15); % 1 camada internas
    nets{i} = configure(nets{i},Ptr,Ttr{i});
end

% 3. Pré-processamento dos Dados
% 3.1) Normalizar os padrões de Treinamento de entrada/saída entre 0 e 1:
for i = 1:3
    for j = 1:size(Ptr(:,i))
    nets{i}.inputs{j}.processParams{2}.ymin = 0;
    nets{i}.inputs{j}.processParams{2}.ymax = 1;
    end
end

% 3.2) Dividir os dados entre os conjuntos de Treino, Validação e Erro de
% Teste:

for i = 1:3
    nets{i}.divideFcn = 'divideind';
    nets{i}.divideParam.trainInd = 1:indiceInicialSim - 1;
    % OBS: Usarei um artificio para passar um "intervalo de tamanho 0"
    nets{i}.divideParam.valInd = 2:1; %não há validação
    nets{i}.divideParam.testInd = 2:1; % não há nada dedicado a teste
end

% 4. Treinamento das redes
for i = 1:3
    nets{i}.trainParam.showWindow = true;   % Exibe a interface de usuário (GUI)
    % Arquitetura da rede e funções de ativação de cada camada:
    nets{i}.layers{1}.dimensions = 15;
    nets{i}.layers{1}.transferFcn = 'tansig';
    nets{i}.layers{2}.transferFcn = 'purelin';  % Output como puramente linear
    nets{i}.performFcn = 'mse';         % Usamos somas quadráticas 
    nets{i}.trainFcn = 'trainlm';       % Algoritmo de otimização usado

    % Hiperparâmetros de treinamentos (Ajustar "na mão"):
    nets{i}.trainParam.epochs = 10000;
    nets{i}.trainParam.time = 120;
    nets{i}.trainParam.lr = 0.2;
    nets{i}.trainParam.min_grad = 10^-11; % O ideal seria 10^-20
    nets{i}.trainParam.max_fail = 1000;

    [nets{i},tr] = train(nets{i},Ptr,Ttr{i});
end

%5. Simulacao das redes neurais:
% Vamos preencher o P e o T simulado aos poucos:
P_simu = P; 
T_simu = T;

for i = 1 : nAmostras
    for j = 1:3
        T_simu{}
    end
end


% Para cada rede (no seu loop):
for i = 1:3

    % Simulando a rede a partir do inicio:
    P_simu = P;
    T_simu = T;
    for j = 1: nAmostras
        T_simu()
    end

    % Agora você tem a saída simulada da rede para o período de previsão
    % Plote a comparação entre os valores reais e previstos
    figure;
    plot(1:nSimulacao, dadosReais, 'b', 'LineWidth', 2); % Dados reais em azul
    hold on;
    plot(1:nSimulacao, saidaSimulada, 'r--', 'LineWidth', 2); % Saída simulada em vermelho com linha tracejada
    legend('Dados Reais', 'Saída Simulada');
    title('Comparação entre Dados Reais e Saída Simulada');
    xlabel('Tempo (dias)');
    ylabel('Valor');
    hold off;
end
Neste código, estamos simulando cada rede neural para o período de previsão (últimos 3 meses) e comparando os valores reais com os valores previstos usando um gráfico. Certifique-se de ajustar isso às suas necessidades específicas e ajustar os detalhes da plotagem, como cores e estilos de linha, conforme desejado.





